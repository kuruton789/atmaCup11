{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"シンプルバージョン（part 6）(tta).ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"}},"cells":[{"cell_type":"markdown","metadata":{"id":"yDpeLJL997R9"},"source":["## これは何?\n","\n","初心者向け講座#1の内容から学習・予測に不要な部分を排除した notebook です。メインの処理を追い駆けたい!という時にお使いください。"]},{"cell_type":"markdown","metadata":{"id":"B_ax013k97SD"},"source":["## Note:\n","\n","**事前学習済みモデルは利用禁止です!**"]},{"cell_type":"markdown","metadata":{"id":"UBxIpTXD97SE"},"source":["### 基本の設定"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vb-RFN9t8fqM","executionInfo":{"status":"ok","timestamp":1626940749356,"user_tz":-540,"elapsed":17113,"user":{"displayName":"クルトン","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHntcg_d2qsxMa-rbEE6tvAWHvAPDuunfEdK0t=s64","userId":"17231302919530674825"}},"outputId":"43f18c5f-8b04-46f1-dca0-05c646153181"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rUxgwNIP97SF"},"source":["import os\n","\n","import pandas as pd\n","import numpy as np\n","from glob import  glob\n","\n","import matplotlib.pyplot as plt\n","import seaborn as sns"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MPBJDHbf97SG"},"source":["### 各種ディレクトリの定義"]},{"cell_type":"code","metadata":{"id":"ckx9RTFv97SG"},"source":["dataset_root = '/content/drive/MyDrive/atmaCup/#11/dataset_atmaCup11'\n","assert dataset_root is not None\n","\n","input_dir = os.path.join(dataset_root, \"inputs\")\n","photo_dir = os.path.join(input_dir, \"photos\")\n","\n","output_dir = os.path.join(dataset_root, \"output_ver6\")\n","os.makedirs(output_dir, exist_ok=True)\n","\n","train_df = pd.read_csv(os.path.join(input_dir, 'train.csv'))\n","test_df = pd.read_csv(os.path.join(input_dir, 'test.csv'))\n","\n","material_df = pd.read_csv(os.path.join(input_dir, 'materials.csv'))\n","technique_df = pd.read_csv(os.path.join(input_dir, 'techniques.csv'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kHkNToWwt_kQ"},"source":["cv_output_dir = os.path.join(dataset_root, \"train_cv\")\n","os.makedirs(cv_output_dir, exist_ok=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"z_NLn3QRE4kf"},"source":["using_models = [os.path.join(output_dir, \"0_10041_0.6963414122757738.pth\"), os.path.join(output_dir, \"1_10033_0.6722119699770754.pth\"), os.path.join(output_dir, \"2_10044_0.7075036053633091.pth\"), os.path.join(output_dir, \"3_10012_0.7235666383645598.pth\"), os.path.join(output_dir, \"4_10017_0.6795332444651865.pth\")]\n","N_TTA = 100"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"p1mQnFAm97SH"},"source":["class Config:\n","    N_FOLDS = 5\n","    N_EPOCHS = 30"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rRvjmMVe97SJ"},"source":["### 画像データの読み込み"]},{"cell_type":"code","metadata":{"id":"F4e-iG-M97SJ"},"source":["from PIL import Image\n","\n","def to_img_path(object_id):\n","    return os.path.join(photo_dir, f'{object_id}.jpg')\n","\n","def read_image(object_id):\n","    return Image.open(to_img_path(object_id))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QnoDcPWyfZ-D","executionInfo":{"status":"ok","timestamp":1626940780087,"user_tz":-540,"elapsed":15489,"user":{"displayName":"クルトン","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHntcg_d2qsxMa-rbEE6tvAWHvAPDuunfEdK0t=s64","userId":"17231302919530674825"}},"outputId":"3f12202a-93a8-4a72-d219-9cfa0547028a"},"source":["!pip uninstall scikit-learn\n","!pip install --pre --extra-index https://pypi.anaconda.org/scipy-wheels-nightly/simple scikit-learn"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Found existing installation: scikit-learn 0.22.2.post1\n","Uninstalling scikit-learn-0.22.2.post1:\n","  Would remove:\n","    /usr/local/lib/python3.7/dist-packages/scikit_learn-0.22.2.post1.dist-info/*\n","    /usr/local/lib/python3.7/dist-packages/sklearn/*\n","Proceed (y/n)? y\n","  Successfully uninstalled scikit-learn-0.22.2.post1\n","Looking in indexes: https://pypi.org/simple, https://pypi.anaconda.org/scipy-wheels-nightly/simple\n","Collecting scikit-learn\n","  Downloading https://pypi.anaconda.org/scipy-wheels-nightly/simple/scikit-learn/1.0.dev0/scikit_learn-1.0.dev0-cp37-cp37m-manylinux2010_x86_64.whl (22.9 MB)\n","\u001b[K     |████████████████████████████████| 22.9 MB 1.4 MB/s \n","\u001b[?25hCollecting threadpoolctl>=2.0.0\n","  Downloading threadpoolctl-2.2.0-py3-none-any.whl (12 kB)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.4.1)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.0.1)\n","Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.19.5)\n","Installing collected packages: threadpoolctl, scikit-learn\n","Successfully installed scikit-learn-1.0.dev0 threadpoolctl-2.2.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aQPiAfLok2ox","executionInfo":{"status":"ok","timestamp":1626940782903,"user_tz":-540,"elapsed":2819,"user":{"displayName":"クルトン","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHntcg_d2qsxMa-rbEE6tvAWHvAPDuunfEdK0t=s64","userId":"17231302919530674825"}},"outputId":"6730c16e-0cb9-48dc-8b76-a0053aefc820"},"source":["!pip install timm"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting timm\n","  Downloading timm-0.4.12-py3-none-any.whl (376 kB)\n","\u001b[?25l\r\u001b[K     |▉                               | 10 kB 36.7 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 20 kB 37.5 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 30 kB 37.2 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 40 kB 23.3 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 51 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 61 kB 17.0 MB/s eta 0:00:01\r\u001b[K     |██████                          | 71 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |███████                         | 81 kB 13.9 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 92 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 102 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 112 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 122 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 133 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 143 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 153 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 163 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 174 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 184 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 194 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 204 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 215 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 225 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 235 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 245 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 256 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 266 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 276 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 286 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 296 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 307 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 317 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 327 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 337 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 348 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 358 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 368 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 376 kB 13.7 MB/s \n","\u001b[?25hRequirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from timm) (1.9.0+cu102)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm) (0.10.0+cu102)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->timm) (3.7.4.3)\n","Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (7.1.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (1.19.5)\n","Installing collected packages: timm\n","Successfully installed timm-0.4.12\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bNuH_S5V97SK"},"source":["import torch\n","from torch import nn\n","from torch.optim import Adam\n","from torch.optim.optimizer import Optimizer\n","from torch.utils import data\n","\n","# torchvision\n","from torchvision import transforms as T\n","# from torchvision.models import resnet34\n","import timm\n","\n","# scikit-learn\n","from sklearn.metrics import mean_squared_error\n","from sklearn.model_selection import KFold, StratifiedGroupKFold"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B6idZnP697SK"},"source":["IMG_MEAN = [0.485, 0.456, 0.406]\n","IMG_STD = [0.229, 0.224, 0.225]\n","\n","class AtmaDataset(data.Dataset):\n","    \"\"\"atmaCup用にデータ読み込み等を行なうデータ・セット\"\"\"\n","    object_path_key = \"object_path\"\n","    label_key = \"target\"\n","\n","    @property\n","    def meta_keys(self):\n","        retval = [self.object_path_key]\n","\n","        if self.is_train:\n","            retval += [self.label_key]\n","\n","        return retval\n","\n","    def __init__(self, meta_df: pd.DataFrame, is_train=True):\n","        \"\"\"\n","        args:\n","            meta_df: \n","                画像へのパスと label 情報が含まれている dataframe\n","                必ず object_path に画像へのパス, target に正解ラベルが入っている必要があります\n","            \n","            is_train:\n","                True のとき学習用のデータ拡張を適用します.\n","                False の時は単に size にリサイズを行います\n","        \"\"\"\n","\n","        self.is_train = is_train\n","        for k in self.meta_keys:\n","            if k not in meta_df:\n","                raise ValueError(\"meta df must have {}\".format(k))\n","\n","        self.meta_df = meta_df.reset_index(drop=True)\n","        self.index_to_data = self.meta_df.to_dict(orient=\"index\")\n","\n","        size = (256, 256)\n","\n","        additional_items = (\n","            [T.Resize(size)]\n","            if not is_train\n","            else [\n","                T.RandomVerticalFlip(),\n","                T.RandomHorizontalFlip(),\n","                T.Resize(size),\n","            ]\n","        )\n","\n","        self.transformer = T.Compose(\n","            [*additional_items, T.ToTensor(), T.Normalize(mean=IMG_MEAN, std=IMG_STD)]\n","        )\n","\n","    def __getitem__(self, index):\n","        data = self.index_to_data[index]\n","\n","        obj_path, label = data.get(self.object_path_key), data.get(self.label_key, -1)\n","        img = Image.open(obj_path)\n","        img = self.transformer(img)\n","        return img, label\n","\n","    def __len__(self):\n","        return len(self.meta_df)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JwwmYu-T97SL"},"source":["# CUDA を使うので確認. google colab の場合 GPU accelerator をオンにしておいてください\n","assert torch.cuda.is_available()\n","\n","DEVICE = torch.device(\"cuda\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Pij6gbpx97SM"},"source":["## Train / Validation Phase"]},{"cell_type":"code","metadata":{"id":"MC-rSZaA97SM"},"source":["def train(\n","    model: nn.Module,\n","    optimizer: Optimizer,\n","    train_loader: data.DataLoader\n",") -> pd.Series:\n","\n","    # train にすることで model 内の学習時にのみ有効な機構が有効になります (Dropouts Layers、BatchNorm Layers...)\n","    model.train()\n","    \n","    criterion = nn.MSELoss()\n","    \n","    for i, (x_i, y_i) in enumerate(train_loader):\n","        x_i = x_i.to(DEVICE)\n","        y_i = y_i.to(DEVICE).reshape(-1, 1).float()\n","\n","        output = model(x_i)\n","        loss = criterion(output, y_i)\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","def predict(model: nn.Module, loader: data.DataLoader) -> np.ndarray:\n","    # train とは逆で model 内の学習時にのみ有効な機構がオフになります (Dropouts Layers、BatchNorm Layers...)\n","    model.eval()\n","    \n","    predicts = []\n","    \n","    for x_i, y_i in loader:\n","        \n","        # 明示的に勾配を計算しないように指定することができます. \n","        # この関数ではモデルの更新はせずに単に出力だけを使いますので勾配は不要です.\n","        with torch.no_grad():\n","            output = model(x_i.to(DEVICE))\n","\n","        predicts.extend(output.data.cpu().numpy())\n","\n","    pred = np.array(predicts).reshape(-1)\n","    return pred\n","\n","\n","def calculate_metrics(y_true, y_pred) -> dict:\n","    \"\"\"正解ラベルと予測ラベルから指標を計算する\"\"\"    \n","    return {\n","        'rmse': mean_squared_error(y_true, y_pred) ** .5\n","    }\n","\n","\n","def valid(\n","    model: nn.Module, \n","    y_valid: np.ndarray, \n","    valid_loader: data.DataLoader\n",") -> pd.Series:\n","    \"\"\"検証フェーズ\n","    与えられたモデル・データローダを使って検証フェーズを実行。スコアの dict と予測した値を返す\n","    \"\"\"\n","    \n","    pred = predict(model, valid_loader)\n","    score = calculate_metrics(y_valid, pred)\n","    return score, pred"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CJUTt_CC97SN"},"source":["## Run Fold\n","\n","1. train / valid の loader 作成\n","2. 以下を epoch 数だけ繰り返す\n","    1. 学習用データで学習 \n","    2. 検証用データで検証スコアの算出"]},{"cell_type":"code","metadata":{"id":"LB-tg_2B97SO"},"source":["# def calc_cv(\n","#     model: nn.Module, \n","#     valid_df: pd.DataFrame, \n","#     y_valid: np.ndarray,\n","#     n_tta: int) -> float:\n","#     \"\"\"\n","#     train / valid に分割されたデータで学習と同時に検証を行なう\n","#     \"\"\"\n","    \n","#     #   : 検証用の方は is_train=False にしてデータ拡張オフにする\n","#     valid_dataset = AtmaDataset(meta_df=valid_df, is_train=False)\n","#     valid_loader = data.DataLoader(valid_dataset, batch_size=256, num_workers=4)\n","    \n","#     # optimizer の定義\n","#     optimizer = Adam(model.parameters(), lr=1e-3)\n","\n","#     best_score = float('inf')\n","#     best_model_path = None\n","#     best_model = None\n","\n","#     model_scores = []\n","\n","#     for epoch in range(1, n_epochs + 1):\n","#         print(f'start {epoch}')\n","        \n","#         # 1: 学習用データで学習を実行。学習時のロスを取得\n","#         train(model, optimizer, train_loader)\n","\n","#         # 2: 検証データでのスコアを計算\n","#         score_valid, y_valid_pred = valid(model=model, valid_loader=valid_loader, y_valid=y_valid)\n","\n","#         model_scores.append(score_valid['rmse'])\n","\n","#         model_path = os.path.join(output_dir, str(i) + '_' + str(epoch) + '_' + str(score_valid['rmse']) + '.pth')\n","\n","#         if best_score > score_valid['rmse']:\n","#             best_score = score_valid['rmse']\n","#             best_model_path = model_path\n","#             best_model = model.state_dict()\n","    \n","#     torch.save(best_model, best_model_path)\n","\n","#     torch.save(model.state_dict(), model_path)\n","\n","#     fig = plt.figure()\n","\n","#     plt.plot(list(range(n_epochs)), model_scores)\n","\n","#     fig.savefig(os.path.join(output_dir, \"scores_(\" + str(i) + \")_\" + str(1) + \"-\" + str(n_epochs) + \").png\"))\n","\n","#     return best_score, best_model_path"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oRy96ia197SP"},"source":["### その他\n","\n","モデル作成などの関数定義"]},{"cell_type":"code","metadata":{"id":"Oh6ztvmE97SP"},"source":["def create_model():\n","    model = timm.create_model('efficientnet_b0', pretrained=False)\n","    num_ftrs = model.classifier.in_features\n","    model.classifier = nn.Linear(in_features=num_ftrs, out_features=1, bias=True)\n","    return model\n","    \n","def create_metadata(input_df):\n","    out_df = input_df[['object_id']].copy()\n","    out_df['object_path'] = input_df['object_id'].map(to_img_path)\n","    \n","    if \"target\" in input_df:\n","        out_df[\"target\"] = (input_df['sorting_date'] - 1550) / 100\n","\n","    return out_df\n","\n","# def run_test_predict(model):\n","#     test_meta_df = create_metadata(test_df)\n","\n","#     # 学習時のデータ拡張はオフにしたいので is_train=False としている\n","#     test_dataset = AtmaDataset(meta_df=test_meta_df, is_train=False)\n","#     test_loader = data.DataLoader(dataset=test_dataset, batch_size=128, drop_last=False, num_workers=4)\n","    \n","#     y_pred = predict(model, loader=test_loader)\n","#     return y_pred"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IFWebsU0D-A0"},"source":["from tqdm import tqdm\n","\n","def run_test_predict(model, input_df, n_tta=0):\n","    # n_tta > 0 の時だけデータ拡張を on にする (is_train = True)\n","    is_tta_mode = n_tta > 0\n","    test_dataset = AtmaDataset(meta_df=input_df, is_train=is_tta_mode)\n","    test_loader = data.DataLoader(dataset=test_dataset, batch_size=128, drop_last=False, num_workers=4)\n","\n","    predictions = []\n","    n_times = 1 if not is_tta_mode else n_tta\n","    print(f\"run #{n_times} times / tta={is_tta_mode}\")\n","    for _ in tqdm(range(n_times)):\n","        y_pred = predict(model, loader=test_loader)\n","        predictions.append(y_pred)\n","\n","    return np.array(predictions).mean(axis=0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wlv6s8_PtzrI","executionInfo":{"status":"ok","timestamp":1626940786449,"user_tz":-540,"elapsed":6,"user":{"displayName":"クルトン","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHntcg_d2qsxMa-rbEE6tvAWHvAPDuunfEdK0t=s64","userId":"17231302919530674825"}},"outputId":"23c9769d-13fc-419f-e5d5-37b1eebe4270"},"source":["train_df.columns"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['object_id', 'sorting_date', 'art_series_id', 'target'], dtype='object')"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"UhFbieZp0FSW"},"source":["def total_rmse(model_scores):\n","    total_rmse = 0\n","    for model_score in model_scores:\n","      total_rmse += model_score ** 2\n","    total_rmse /= 5\n","    total_rmse = total_rmse ** 0.5\n","    print('total_rmse: ' + str(total_rmse))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":395},"id":"3XaI78AG97SQ","executionInfo":{"status":"error","timestamp":1626940793599,"user_tz":-540,"elapsed":7154,"user":{"displayName":"クルトン","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgHntcg_d2qsxMa-rbEE6tvAWHvAPDuunfEdK0t=s64","userId":"17231302919530674825"}},"outputId":"854369dd-eed3-4cdf-fbeb-9e27bca3b1ff"},"source":["train_meta_df = create_metadata(train_df)\n","\n","fold = StratifiedGroupKFold(n_splits=5, shuffle=False)\n","cv = list(fold.split(X=train_df, y=train_df['target'], groups=train_df['art_series_id']))[:Config.N_FOLDS]\n","\n","model_scores = []\n","\n","for i, (idx_tr, idx_valid) in enumerate(cv):\n","    model = create_model()\n","    model.to(DEVICE)\n","    model_path = using_models[i]\n","    print(model_path)\n","    model.load_state_dict(torch.load(model_path))\n","\n","    valid_meta_df=train_meta_df.iloc[idx_valid]\n","    y_valid=train_meta_df['target'].values[idx_valid]\n","    \n","    y_pred_tta = run_test_predict(model, valid_meta_df, n_tta=N_TTA)\n","\n","    pd.DataFrame({\n","        \"target\": y_pred_tta\n","    }).to_csv(os.path.join(cv_output_dir, \"part6_\" + str(i) + \"_ver3.csv\"), index=False)\n","    \n","    model_score = calculate_metrics(y_valid, y_pred_tta)\n","\n","    model_scores.append(model_score['rmse'])"],"execution_count":null,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-6056d19bf9fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0midx_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx_valid\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0musing_models\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    850\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 852\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    853\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m     def register_backward_hook(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    550\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    848\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m    849\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m--> 850\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"FsCjQKGlCBzE"},"source":["model_scores"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nS80OiGwIinl"},"source":["total_rmse(model_scores)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ws1IV0_WzhEQ","colab":{"base_uri":"https://localhost:8080/"},"outputId":"75b01f75-b747-4760-c273-3e07015c9162"},"source":["test_predictions = []\n","\n","test_meta_df = create_metadata(test_df)\n","test_meta_df['target'] = np.nan\n","\n","for i in range(5):\n","    model = create_model()\n","    model.to(DEVICE)\n","    model_path = using_models[i]\n","    print(model_path)\n","    model.load_state_dict(torch.load(model_path))\n","    \n","    # 2. モデルで予測 (本当はローカルに保存した重みを読みだすなどするほうがあとで振り返りやすいが簡易にそのまま予測する)\n","    y_pred_i = run_test_predict(model, test_meta_df, n_tta=N_TTA)\n","\n","    pd.DataFrame({\n","        \"target\": y_pred_i\n","    }).to_csv(os.path.join(output_dir, using_models[i] + \"_tta_100.csv\"), index=False)\n","    \n","    test_predictions.append(y_pred_i)\n","    del model"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","\r  0%|          | 0/100 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["/content/drive/MyDrive/atmaCup/#11/dataset_atmaCup11/output_ver6/0_10041_0.6963414122757738.pth\n","run #100 times / tta=True\n"],"name":"stdout"},{"output_type":"stream","text":[" 45%|████▌     | 45/100 [23:45<18:59, 20.72s/it]"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"sUjisXcs97SR"},"source":["# すべての予測の平均値を使う\n","pred_mean = np.array(test_predictions).mean(axis=0)\n","\n","pd.DataFrame({\n","    \"target\": pred_mean\n","}).to_csv(os.path.join(output_dir, \"submission20210722_1730.csv\"), index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BwSa7j7G_cQe"},"source":[""],"execution_count":null,"outputs":[]}]}